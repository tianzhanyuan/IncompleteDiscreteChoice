{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tianzhanyuan/IncompleteDiscreteChoice/blob/main/IdentifiedSet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inequalities $\\to$ Identified Set\n",
        "\n",
        "We saw how to derive the sharp identifying restrictions (inequalities) from a graph. Suppose $P(\\cdot|x)$ is known. The _sharp identified set_ $\\Theta_I(P)$ is the set of $\\theta$ values that are compatible with $P$ and all model restrictions. That is,\n",
        "$$\\Theta_I(P)\\equiv\\{\\theta:P(A|x)\\ge \\nu_\\theta(A|x),~x\\in\\mathcal X, A\\subseteq \\mathcal Y\\}.$$\n",
        "\n",
        "Let's try to obtain this set. First, we load the `idc` library."
      ],
      "metadata": {
        "id": "ac-h03QYyxiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize\n",
        "!git clone https://github.com/hkaido0718/IncompleteDiscreteChoice.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d88ItyJcP9jF",
        "outputId": "197c8307-8654-4b1d-b5e2-edd8f38ca1be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.7.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.7.0 scikit-optimize-0.10.2\n",
            "Cloning into 'IncompleteDiscreteChoice'...\n",
            "remote: Enumerating objects: 430, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 430 (delta 14), reused 12 (delta 12), pack-reused 401 (from 2)\u001b[K\n",
            "Receiving objects: 100% (430/430), 1.28 MiB | 9.83 MiB/s, done.\n",
            "Resolving deltas: 100% (237/237), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Entry game\n",
        "\n",
        "We used $(F_\\theta(a),F_\\theta(b),F_\\theta(c),F_\\theta(d),F_\\theta(e))=(0.1, 0.2, 0.3, 0.15, 0.25)$, which was arbitrary. Let's derive the probability allocation from a parametric model.\n",
        "\n",
        "Earlier, we considered the following regions\n",
        "\\begin{align*}\n",
        "\\text{region00} &= \\{U_1 \\leq -x_1\\beta_1, U_2 \\leq -x_2\\beta_2\\} \\\\\n",
        "\\text{region01} &= \\{U_1 \\leq -x_1\\beta_1 - \\delta_1,U_2 \\geq -x_2\\beta_2\\} \\\\\n",
        "\\text{region10} &= \\{U_1 \\geq -x_1\\beta_1, U_2 \\leq -x_2\\beta_2 - \\delta_2\\} \\\\\n",
        "\\text{region11} &= \\{U_1 \\geq -x_1\\beta_1 - \\delta_1, U_2 \\geq -x_2\\beta_2 - \\delta_2\\}\n",
        "\\end{align*}\n",
        "\n",
        "\n",
        "\n",
        "Suppose $(U_1,U_2)$ is a bivariate normal distribution with mean 0, variance 1, and correlation $\\rho$.\n",
        "Define the following $U$-nodes\n",
        "\\begin{align}\n",
        "a &= \\text{region00}\\\\\n",
        "b &= \\text{region01} \\setminus \\text{region10}\\\\\n",
        "c &= \\text{region10} \\setminus \\text{region01}\\\\\n",
        "d &= \\text{region11}\\\\\n",
        "e &= \\text{region01} \\cap \\text{region10}.\n",
        "\\end{align}\n",
        "We can calculate the probability distribution over the nodes under the normality assumption. The function `ex.calculate_Ftheta_entrygame` does this job. An example is given below."
      ],
      "metadata": {
        "id": "MliseylAzjSf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GNjnb3V_yv-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b080ef-d02c-4285-c022-74b39692f961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.19166077 0.04242391 0.62912113 0.09455516 0.04224037]\n"
          ]
        }
      ],
      "source": [
        "import IncompleteDiscreteChoice.examples as ex\n",
        "\n",
        "# Example usage\n",
        "beta1 = 0.75\n",
        "beta2 = 0.25\n",
        "delta1 = -0.5\n",
        "delta2 = -1\n",
        "rho = 0.5\n",
        "\n",
        "X1 = 1\n",
        "X2 = -1\n",
        "X = [X1,X2]\n",
        "theta_true = [beta1, beta2, delta1, delta2, rho]\n",
        "Ftheta = ex.calculate_Ftheta_entrygame(X, theta_true)\n",
        "print(Ftheta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's combine this function with the one that yields the sharp lower bounds for the conditional probabilities. For this, we first represent the model by a graph."
      ],
      "metadata": {
        "id": "eUN9D3wLQQwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IncompleteDiscreteChoice.idclib as idc\n",
        "# Define the model\n",
        "Y_nodes = [(0,0), (0,1), (1,0), (1,1)]\n",
        "U_nodes = ['a', 'b', 'c', 'd', 'e']\n",
        "edges = [\n",
        "    ('a', (0,0)),\n",
        "    ('b', (0,1)),\n",
        "    ('c', (1,0)),\n",
        "    ('d', (1,1)),\n",
        "    ('e', (0,1)),\n",
        "    ('e', (1,0))\n",
        "]\n",
        "gmodel = idc.BipartiteGraph(Y_nodes, U_nodes, edges)"
      ],
      "metadata": {
        "id": "zmTRAmTKOee9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, for any $\\theta$, we can calculates the sharp identifying restrictions (lower bounds)."
      ],
      "metadata": {
        "id": "HpiiWXY_pw_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the calculate_sharp_lower_bound to calculate probabilities.\n",
        "results,sharp_lower_bounds = gmodel.calculate_sharp_lower_bound(Ftheta)\n",
        "\n",
        "# Show results\n",
        "idc.print_table(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpGSs7KWp7xm",
        "outputId": "67339b09-0d2b-4b12-97db-1f82877b38fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset of Y-nodes                    Exclusive U-nodes             Sharp Lower Bound  \n",
            "======================================================================================\n",
            "{(0, 0)}                             {'a'}                         0.192              \n",
            "{(0, 1)}                             {'b'}                         0.042              \n",
            "{(1, 0)}                             {'c'}                         0.629              \n",
            "{(1, 1)}                             {'d'}                         0.095              \n",
            "{(0, 1), (0, 0)}                     {'a', 'b'}                    0.234              \n",
            "{(1, 0), (0, 0)}                     {'a', 'c'}                    0.821              \n",
            "{(1, 1), (0, 0)}                     {'a', 'd'}                    0.286              \n",
            "{(0, 1), (1, 0)}                     {'b', 'e', 'c'}               0.714              \n",
            "{(0, 1), (1, 1)}                     {'b', 'd'}                    0.137              \n",
            "{(1, 0), (1, 1)}                     {'d', 'c'}                    0.724              \n",
            "{(0, 1), (1, 0), (0, 0)}             {'a', 'b', 'e', 'c'}          0.905              \n",
            "{(0, 1), (1, 1), (0, 0)}             {'a', 'b', 'd'}               0.329              \n",
            "{(1, 0), (1, 1), (0, 0)}             {'d', 'a', 'c'}               0.915              \n",
            "{(0, 1), (1, 0), (1, 1)}             {'d', 'b', 'e', 'c'}          0.808              \n",
            "{(0, 1), (1, 0), (1, 1), (0, 0)}     {'a', 'c', 'e', 'b', 'd'}     1.000              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's try to get the identified set. Suppose the true DGP is such that it selects (1,0) whenever multiple equilibria exist. Then, the probability allocation is\n",
        "\\begin{align}\n",
        "P((0,0)|x)&=F_\\theta(a|x)\\\\\n",
        "P((0,1)|x)&=F_\\theta(b|x)\\\\\n",
        "P((1,0)|x)&=F_\\theta(c|x)+F_\\theta(e|x)\\\\\n",
        "P((1,1)|x)&=F_\\theta(d|x).\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "Lz5oQg6M1UFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P0 = sharp_lower_bounds[1:5]\n",
        "P0[2] = 1 - (P0[0] + P0[1] + P0[3])\n",
        "print(P0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fZk1UXD2DRb",
        "outputId": "97d8af48-6c28-4db9-c06f-b4623c541ef9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.19166077 0.04242391 0.67136015 0.09455516]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's calculate the probabilities of all events under $P$.\n"
      ],
      "metadata": {
        "id": "KP8JLAhk3Uy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results, subset_probabilities = idc.calculate_subset_probabilities(P0, Y_nodes)\n",
        "\n",
        "print(f\"{'Subset of Y-nodes':<45} {'P(A|x)':<20}\")\n",
        "print(\"=\"*65)\n",
        "for subset_set, subset_prob in results:\n",
        "    print(f\"{str(subset_set):<45} {subset_prob:<20.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNbUPXb83efn",
        "outputId": "fb527fc9-d717-40cb-df94-bfa1adbb608f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset of Y-nodes                             P(A|x)              \n",
            "=================================================================\n",
            "()                                            0.000               \n",
            "((0, 0),)                                     0.192               \n",
            "((0, 1),)                                     0.042               \n",
            "((1, 0),)                                     0.671               \n",
            "((1, 1),)                                     0.095               \n",
            "((0, 0), (0, 1))                              0.234               \n",
            "((0, 0), (1, 0))                              0.863               \n",
            "((0, 0), (1, 1))                              0.286               \n",
            "((0, 1), (1, 0))                              0.714               \n",
            "((0, 1), (1, 1))                              0.137               \n",
            "((1, 0), (1, 1))                              0.766               \n",
            "((0, 0), (0, 1), (1, 0))                      0.905               \n",
            "((0, 0), (0, 1), (1, 1))                      0.329               \n",
            "((0, 0), (1, 0), (1, 1))                      0.958               \n",
            "((0, 1), (1, 0), (1, 1))                      0.808               \n",
            "((0, 0), (0, 1), (1, 0), (1, 1))              1.000               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare this to the sharp lower bound. Not surprisingly, the conditional probability $P(A|x)$ is above the sharp lower bound for any event. Hence, $\\theta=(0.75, 0.25, -0.5, -1, 0.5)$ is in $\\Theta_I(P)$. Now, lets see if there are other parameter values that are in the sharp identified set.\n",
        "\n",
        "For simplicity, suppose $\\beta_1=0.75$, $\\beta_2=0.25$, and $\\rho=0.5$ is known. The following code calculates the set of $(\\delta_1,\\delta_2)$ that are compatible with the sharp identifying restrictions."
      ],
      "metadata": {
        "id": "TAavnDHUE2-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is hard to plot $\\Theta_I(P_0)$, but we can get its projection (to the $j$-th coordinate) by solving the following optimization problem.\n",
        "\n",
        "\\begin{align*}\\max/\\min_{\\theta\\in\\Theta} &~\\theta_j\\\\\n",
        "s.t.&~P(A|x)\\ge \\nu_\\theta(A|x),~x\\in\\mathcal X, A\\subseteq \\mathcal Y.\n",
        "\\end{align*}\n",
        "\n",
        "The following code computes the projection of the sharp identification region for a component of your choice (there will be a prompt to choose the component)."
      ],
      "metadata": {
        "id": "JV9X7RWIVI3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize, NonlinearConstraint\n",
        "from itertools import product\n",
        "\n",
        "# Define your lower and upper bounds\n",
        "lower = np.array([-2, -2, -2.5, -2.5, 0.01])\n",
        "upper = np.array([2, 2, -0.01, -0.01, 0.8])\n",
        "\n",
        "# X values\n",
        "values = [-1,1]\n",
        "X_values = list(product(values, values))\n",
        "\n",
        "# Set P0(A|X)\n",
        "subset_probabilities_all = []\n",
        "for X in X_values:\n",
        "    Ftheta = ex.calculate_Ftheta_entrygame(np.array(X), theta_true)\n",
        "    _, sharp_lower_bounds = gmodel.calculate_sharp_lower_bound(Ftheta)\n",
        "    P0 = sharp_lower_bounds[1:5]\n",
        "    P0[2] = 1 - (P0[0] + P0[1] + P0[3])\n",
        "    _, subset_probabilities = idc.calculate_subset_probabilities(P0, Y_nodes)\n",
        "    subset_probabilities_all.append(subset_probabilities)\n",
        "\n",
        "# Function to create the objective function based on the user-selected component\n",
        "def create_objective_function(component_index, maximize=True):\n",
        "    if maximize:\n",
        "        return lambda theta: -theta[component_index]\n",
        "    else:\n",
        "        return lambda theta: theta[component_index]\n",
        "\n",
        "# Define the constraint function\n",
        "def constraint(theta):\n",
        "    sharp_lower_bounds_all = []\n",
        "    for X in X_values:\n",
        "        Ftheta = ex.calculate_Ftheta_entrygame(np.array(X), theta)\n",
        "        _, sharp_lower_bounds = gmodel.calculate_sharp_lower_bound(Ftheta)\n",
        "        sharp_lower_bounds_all.append(sharp_lower_bounds)\n",
        "\n",
        "    constraints = np.array(sharp_lower_bounds_all) - np.array(subset_probabilities_all)\n",
        "    # Stack constraints into a single array\n",
        "    return np.hstack(constraints)\n",
        "\n",
        "# Define the bounds for the optimization\n",
        "bounds = [(l, u) for l, u in zip(lower, upper)]\n",
        "\n",
        "# Create a NonlinearConstraint object\n",
        "nonlinear_constraint = NonlinearConstraint(constraint, -np.inf, 1e-4)\n",
        "\n",
        "# Define initial guess for theta\n",
        "initial_theta = np.mean([lower, upper], axis=0)\n",
        "\n",
        "# User specifies the component of theta to optimize\n",
        "component_index = int(input(\"Enter the component index of theta to optimize (0-based index): \"))\n",
        "\n",
        "# Run the optimization for maximization\n",
        "objective_max = create_objective_function(component_index, maximize=True)\n",
        "result_max = minimize(objective_max, initial_theta, method='trust-constr', bounds=bounds, constraints=[nonlinear_constraint], options={'verbose': 1})\n",
        "\n",
        "# Run the optimization for minimization\n",
        "objective_min = create_objective_function(component_index, maximize=False)\n",
        "result_min = minimize(objective_min, initial_theta, method='trust-constr', bounds=bounds, constraints=[nonlinear_constraint], options={'verbose': 1})\n",
        "\n",
        "# Check if the optimization for maximization was successful\n",
        "if result_max.success:\n",
        "    max_theta_value = -result_max.fun\n",
        "    optimized_theta_max = result_max.x\n",
        "    print(f\"The maximum value of the component {component_index} of theta that satisfies the condition is: {max_theta_value}\")\n",
        "else:\n",
        "    print(\"Maximization optimization failed.\")\n",
        "    print(result_max.message)\n",
        "\n",
        "# Check if the optimization for minimization was successful\n",
        "if result_min.success:\n",
        "    min_theta_value = result_min.fun\n",
        "    optimized_theta_min = result_min.x\n",
        "    print(f\"The minimum value of the component {component_index} of theta that satisfies the condition is: {min_theta_value}\")\n",
        "else:\n",
        "    print(\"Minimization optimization failed.\")\n",
        "    print(result_min.message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uBQ3rwxXZS_",
        "outputId": "7b3d73e3-aaec-402a-9c90-9cedef876c48"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the component index of theta to optimize (0-based index): 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/optimize/_differentiable_functions.py:376: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
            "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constraint violation exceeds 'gtol'\n",
            "Number of iterations: 447, function evaluations: 2682, CG iterations: 449, optimality: 5.10e-13, constraint violation: 3.17e-01, execution time: 1.6e+02 s.\n",
            "Constraint violation exceeds 'gtol'\n",
            "Number of iterations: 463, function evaluations: 2778, CG iterations: 462, optimality: 4.34e-11, constraint violation: 3.18e-01, execution time: 1.7e+02 s.\n",
            "Maximization optimization failed.\n",
            "Constraint violation exceeds 'gtol'\n",
            "Minimization optimization failed.\n",
            "Constraint violation exceeds 'gtol'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, the projection of $\\Theta_I(P_0)$ to the 3rd coordinate (i.e., $\\delta_1$; use 2 (0-based index) as an input above) is $[-0.501,-0.498]$."
      ],
      "metadata": {
        "id": "S3UNl4PEhL61"
      }
    }
  ]
}