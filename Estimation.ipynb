{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tianzhanyuan/IncompleteDiscreteChoice/blob/main/Estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb3pydeIf2G8"
      },
      "source": [
        "# Estimation\n",
        "\n",
        "The goal of this note is to estimate the identified set using a method by Chernozhukov, Hong, and Tamer (2007) (CHT below). Their idea is to define a sample criterion function\n",
        "\\begin{align}\n",
        "\\hat Q_n(\\theta)\n",
        "\\end{align}\n",
        "and use its level set as an estimator of $\\Theta_I(P)$.\n",
        "\n",
        "Below, we\n",
        "- generate data\n",
        "- compute conditional choice probabilities (CCPs)\n",
        "- compare CCPs with the sharp lower bound\n",
        "- define a sample criterion function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja68lsaG-0W8"
      },
      "source": [
        "# Data generation\n",
        "\n",
        "Suppose a sample is generated from an entry game.\n",
        "For this, let's simulate data from the following game.\n",
        "\n",
        "|  | $Y_2=0$ | $Y_2=1$ |\n",
        "|----------|----------|----------|\n",
        "| Enter ($Y_1=0$)  | $(0,0)$   | $(0,X_2'\\beta_2+U_2)$   |\n",
        "| Do not enter ($Y_1=1$)  | $(X_1'\\beta_1+U_1, 0)$  | $(X_1'\\beta_1+\\Delta_1+U_1,X_2'\\beta_2+\\Delta_2+U_2)$  |\n",
        "\n",
        "We set\n",
        "- $X=(X_1,X_2)$ where $X_{j},j=1,2$ are independent Bernoulli random variables.\n",
        "- $\\beta_1$ = 0.75\n",
        "- $\\beta_2$ = 0.25\n",
        "- $\\Delta_1$ = -0.5\n",
        "- $\\Delta_2$ = -0.5\n",
        "- $\\rho$ = 0.5 ($U_1$ and $U_2$'s correlation)\n",
        "\n",
        "The following code generates data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfxkmyqdCtV7",
        "outputId": "94502f9f-e642-4c67-de0d-e94682a665cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]\n",
            " [1. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def simulate_y(n, beta1, beta2, delta1, delta2, rho, Y_nodes, seed=None):\n",
        "    \"\"\"\n",
        "    Simulate Y based on given parameters and regions, and store X and Y values.\n",
        "\n",
        "    Parameters:\n",
        "    n (int): Number of simulations\n",
        "    rho (float): Correlation coefficient between U1 and U2\n",
        "    beta1 (float): Coefficient for U1\n",
        "    beta2 (float): Coefficient for U2\n",
        "    delta1 (float): Threshold adjustment for region01\n",
        "    delta2 (float): Threshold adjustment for region10\n",
        "    Y_nodes (list of tuples): Possible values for Y\n",
        "    seed (int, optional): Seed for the random number generator\n",
        "\n",
        "    Returns:\n",
        "    tuple: Two numpy arrays, X_vals and Y, both of shape (n, 2)\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    # Covariance matrix for the bivariate normal distribution\n",
        "    cov = [[1, rho], [rho, 1]]\n",
        "\n",
        "    # Storage for the results\n",
        "    Y = np.zeros((n, 2))\n",
        "    X_vals = np.zeros((n, 2))\n",
        "\n",
        "    # Simulation\n",
        "    for i in range(n):\n",
        "        # Generate U from a bivariate normal distribution\n",
        "        U = np.random.multivariate_normal([0, 0], cov)\n",
        "\n",
        "        # Generate X from independent Bernoulli distributions\n",
        "        X = np.random.binomial(1, 0.5, 2)\n",
        "        #X = np.random.standard_normal(2)\n",
        "        X_vals[i] = X\n",
        "\n",
        "        # Calculate the threshold values for regions\n",
        "        threshold1_00 = -X[0] * beta1\n",
        "        threshold2_00 = -X[1] * beta2\n",
        "        threshold1_01 = -X[0] * beta1 - delta1\n",
        "        threshold2_10 = -X[1] * beta2 - delta2\n",
        "\n",
        "        # Determine the region and assign Y\n",
        "        if U[0] <= threshold1_00 and U[1] <= threshold2_00:\n",
        "            Y[i] = Y_nodes[0]\n",
        "        elif U[0] <= threshold1_01 and U[1] >= threshold2_00 and not (U[0] >= threshold1_00 and U[1] <= threshold2_10):\n",
        "            Y[i] = Y_nodes[1]\n",
        "        elif U[0] >= threshold1_00 and U[1] <= threshold2_10 and not (U[0] <= threshold1_01 and U[1] >= threshold2_00):\n",
        "            Y[i] = Y_nodes[2]\n",
        "        elif U[0] >= threshold1_01 and U[1] >= threshold2_10:\n",
        "            Y[i] = Y_nodes[3]\n",
        "        elif (U[0] <= threshold1_01 and U[1] >= threshold2_00) and (U[0] >= threshold1_00 and U[1] <= threshold2_10):\n",
        "            Y[i] = Y_nodes[np.random.choice([1, 2])]\n",
        "\n",
        "    return X_vals, Y\n",
        "\n",
        "# Example usage\n",
        "n = 1000\n",
        "beta1 = 0.75\n",
        "beta2 = 0.25\n",
        "delta1 = -0.5\n",
        "delta2 = -0.5\n",
        "rho = 0.5\n",
        "theta_true = [beta1, beta2, delta1, delta2, rho]\n",
        "Y_nodes = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
        "seed = 123\n",
        "\n",
        "# Simulate the values\n",
        "X, Y = simulate_y(n, rho, beta1, beta2, delta1, delta2, Y_nodes,seed=seed)\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yhdjBqDhJvd"
      },
      "source": [
        "# Computing CCP\n",
        "Now let's compute the sample conditional choice probabilities, which we can use to construct a sample criterion function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_4pDFqeZl-p",
        "outputId": "e79e0ce4-f331-46e8-ab88-f313229b6c58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.12/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.7.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "fatal: destination path 'IncompleteDiscreteChoice' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize\n",
        "!git clone https://github.com/hkaido0718/IncompleteDiscreteChoice.git\n",
        "import IncompleteDiscreteChoice.idclib as idc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idc library has a function called calculate_ccp. For this, we should pass the data ($Y,X$) and their support."
      ],
      "metadata": {
        "id": "fHvsZ7U9hLne"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD4rDHsAhLmd",
        "outputId": "966d94ab-d521-4edd-e400-bbd83a4e839f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(Y|X=(np.float64(0.0), np.float64(1.0))) = {(0, 0): 0.08171206225680934, (0, 1): 0.3852140077821012, (1, 0): 0.26459143968871596, (1, 1): 0.26848249027237353}\n",
            "P(Y|X=(np.float64(1.0), np.float64(1.0))) = {(0, 0): 0.05982905982905983, (0, 1): 0.15384615384615385, (1, 0): 0.33760683760683763, (1, 1): 0.44871794871794873}\n",
            "P(Y|X=(np.float64(0.0), np.float64(0.0))) = {(0, 0): 0.1857707509881423, (0, 1): 0.2924901185770751, (1, 0): 0.391304347826087, (1, 1): 0.13043478260869565}\n",
            "P(Y|X=(np.float64(1.0), np.float64(0.0))) = {(0, 0): 0.10546875, (0, 1): 0.15625, (1, 0): 0.53515625, (1, 1): 0.203125}\n",
            "[(np.float64(0.0), np.float64(0.0)), (np.float64(0.0), np.float64(1.0)), (np.float64(1.0), np.float64(0.0)), (np.float64(1.0), np.float64(1.0))]\n",
            "[0.253 0.257 0.256 0.234]\n",
            "[[0.18577075 0.29249012 0.39130435 0.13043478]\n",
            " [0.08171206 0.38521401 0.26459144 0.26848249]\n",
            " [0.10546875 0.15625    0.53515625 0.203125  ]\n",
            " [0.05982906 0.15384615 0.33760684 0.44871795]]\n"
          ]
        }
      ],
      "source": [
        "conditional_probabilities,ccp_array, Px, X_supp = idc.calculate_ccp(Y,X, Y_nodes)\n",
        "\n",
        "# Print the conditional probabilities for the specified X support\n",
        "for x in list(conditional_probabilities.keys())[:5]:\n",
        "    print(f\"P(Y|X={x}) = {conditional_probabilities[x]}\")\n",
        "\n",
        "# Support of X and X's marginal distribution over it\n",
        "print(X_supp)\n",
        "print(Px)\n",
        "\n",
        "# This is the CCP matrix (sorted according to X_supp)\n",
        "print(ccp_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUktkjH3zXmC"
      },
      "source": [
        "From the CCP, we can compute the conditional probability of all events $P(A|X_i),A\\subseteq\\mathcal Y$ for each $X_i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aDTNoutXkhWW",
        "outputId": "d374228e-673f-496f-df5e-1f09ab14e6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.18577075 0.29249012 0.39130435 0.13043478 0.47826087\n",
            " 0.5770751  0.31620553 0.68379447 0.4229249  0.52173913 0.86956522\n",
            " 0.60869565 0.70750988 0.81422925 1.        ]\n",
            "[[0.         0.18577075 0.29249012 0.39130435 0.13043478 0.47826087\n",
            "  0.5770751  0.31620553 0.68379447 0.4229249  0.52173913 0.86956522\n",
            "  0.60869565 0.70750988 0.81422925 1.        ]\n",
            " [0.         0.08171206 0.38521401 0.26459144 0.26848249 0.46692607\n",
            "  0.3463035  0.35019455 0.64980545 0.6536965  0.53307393 0.73151751\n",
            "  0.73540856 0.61478599 0.91828794 1.        ]\n",
            " [0.         0.10546875 0.15625    0.53515625 0.203125   0.26171875\n",
            "  0.640625   0.30859375 0.69140625 0.359375   0.73828125 0.796875\n",
            "  0.46484375 0.84375    0.89453125 1.        ]\n",
            " [0.         0.05982906 0.15384615 0.33760684 0.44871795 0.21367521\n",
            "  0.3974359  0.50854701 0.49145299 0.6025641  0.78632479 0.55128205\n",
            "  0.66239316 0.84615385 0.94017094 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "_, temp = idc.calculate_subset_probabilities(ccp_array[0,:], Y_nodes)\n",
        "print(temp)\n",
        "J = len(temp) # This is the number of all events\n",
        "\n",
        "Nx = len(ccp_array) # number of unique X values (n for continous X)\n",
        "p_events = np.zeros((Nx,J))\n",
        "for i in range(Nx):\n",
        "  _, p_events[i,:] = idc.calculate_subset_probabilities(ccp_array[i,:], Y_nodes)\n",
        "\n",
        "# Printing p(A|x) as an Nx-by-J array\n",
        "print(p_events)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0ftK4DVZiZW"
      },
      "source": [
        "# Compute sharp lower bound $\\nu_\\theta(A|x)$\n",
        "Now, let's compare $P(A|X_i)$ to the sharp lower bound calculated at some value $\\theta$. For the moment, we use the following value as $\\theta$ (you can change it to something else.)\n",
        "- $\\beta_1$ = 0.5\n",
        "- $\\beta_2$ = 0.5\n",
        "- $\\Delta_1$ = -0.25\n",
        "- $\\Delta_2$ = -0.5\n",
        "- $\\rho$ = 0.5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DYC7rSxcF14"
      },
      "source": [
        "As before let's build a model as a graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "CNlRSA4kb1SO"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "Y_nodes = [(0,0), (0,1), (1,0), (1,1)]\n",
        "U_nodes = ['a', 'b', 'c', 'd', 'e']\n",
        "edges = [\n",
        "    ('a', (0,0)),\n",
        "    ('b', (0,1)),\n",
        "    ('c', (1,0)),\n",
        "    ('d', (1,1)),\n",
        "    ('e', (0,1)),\n",
        "    ('e', (1,0))\n",
        "]\n",
        "gmodel = idc.BipartiteGraph(Y_nodes, U_nodes, edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGI0KEdscVAe"
      },
      "source": [
        "The next step is to calculate the probability distribution $F_\\theta(\\cdot|X_i)$ over the $U$-nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_I9N4PTcZhy",
        "outputId": "8c19e48b-092d-41a7-f427-452b7a2e0e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.33333217 0.19694609 0.25122617 0.19659913 0.02189845]\n",
            " [0.22687747 0.32529884 0.14563479 0.28116187 0.02103467]\n",
            " [0.22688203 0.10152299 0.40061467 0.25237197 0.01861066]\n",
            " [0.16331975 0.18369635 0.25212357 0.37986425 0.02099885]]\n"
          ]
        }
      ],
      "source": [
        "import IncompleteDiscreteChoice.examples as idcex\n",
        "\n",
        "theta_temp = [0.5,0.5,-0.25,-0.5,0.5]\n",
        "Nu = len(U_nodes)\n",
        "Ftheta = np.zeros((Nx,Nu))\n",
        "for i in range(Nx):\n",
        "  Ftheta[i,:] = idcex.calculate_Ftheta_entrygame(X_supp[i],theta_temp)\n",
        "\n",
        "# Print Ftheta as Nx-by-Nu array\n",
        "print(Ftheta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oli2qywycqbj"
      },
      "source": [
        "Now we are ready to compute the sharp lower bound of CCPs at $\\theta$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPFL4Wmucv0G",
        "outputId": "7dad6f6d-3091-45ab-9534-6e7d1910c0a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.33333217 0.19694609 0.25122617 0.19659913 0.53027827\n",
            "  0.58455834 0.5299313  0.47007071 0.39354523 0.4478253  0.80340289\n",
            "  0.7268774  0.78115747 0.66666985 1.00000202]\n",
            " [0.         0.22687747 0.32529884 0.14563479 0.28116187 0.55217631\n",
            "  0.37251227 0.50803934 0.49196831 0.60646071 0.42679666 0.71884578\n",
            "  0.83333818 0.65367413 0.77313017 1.00000764]\n",
            " [0.         0.22688203 0.10152299 0.40061467 0.25237197 0.32840503\n",
            "  0.6274967  0.479254   0.52074832 0.35389496 0.65298663 0.74763035\n",
            "  0.58077699 0.87986867 0.77312029 1.00000232]\n",
            " [0.         0.16331975 0.18369635 0.25212357 0.37986425 0.3470161\n",
            "  0.41544331 0.543184   0.45681877 0.56356061 0.63198782 0.62013851\n",
            "  0.72688035 0.79530757 0.83668302 1.00000277]]\n"
          ]
        }
      ],
      "source": [
        "nutheta = np.zeros((Nx,J))\n",
        "for i in range(Nx):\n",
        "    _,nutheta[i,:] = gmodel.calculate_sharp_lower_bound(Ftheta[i])\n",
        "\n",
        "# Print lower bound as Nx-by-J array (compare it to p(A|x) above)\n",
        "print(nutheta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4j6M8yDrDP2"
      },
      "source": [
        "Now let's compare the CCP and lower bounds and compute $\\hat Q_n(\\theta)=\\frac{1}{n}\\sum_{j}\\sum_{x\\in\\mathcal X}w_x(\\nu_\\theta(A_j|x)-\\hat P_n(A_j|x))_+$,\n",
        "where $w_x=\\sum_{i}1\\{X_i=x\\}/n$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQlwG4M2tImH",
        "outputId": "5b60f2b5-97fa-4c14-8292-b2e7b2589eb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0005659745511206444\n"
          ]
        }
      ],
      "source": [
        "difference = nutheta - p_events\n",
        "diff_pos = np.maximum(difference, 0)\n",
        "w = np.repeat(Px,J).reshape(Nx,J)\n",
        "n = len(Y)\n",
        "Qhat = np.sum(w*diff_pos)/n\n",
        "print(Qhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXAGIe0LkAQC"
      },
      "source": [
        "# Summary\n",
        "\n",
        "Let's summarize what we did:\n",
        "- We computed $\\hat p(A|x)$\n",
        "- We computed $\\nu_\\theta(A|x)$ at $\\theta$\n",
        "- We computed $\\hat Q_n(\\theta)$\n",
        "\n",
        "The IDC library has a wrapper function `idc.calculate_Qhat` to execute the steps avove.\n",
        "\n",
        "It takes the following objects as inputs\n",
        "- theta: (parameter)\n",
        "- [Y,X]: (data)\n",
        "- gmodel: (class BipartiteGraph)\n",
        "  - Y-nodes\n",
        "  - U-nodes\n",
        "  - Edges\n",
        "- calculate_Ftheta (function)\n",
        "\n",
        "You can simply execute the following code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmRr59lJnrYV",
        "outputId": "548797cc-2f07-462e-b9ab-8a16a04c2b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0005659725348612432\n"
          ]
        }
      ],
      "source": [
        "# If needed uncomment the line below\n",
        "#!git clone https://github.com/hkaido0718/IncompleteDiscreteChoice.git\n",
        "import IncompleteDiscreteChoice.idclib as idc\n",
        "import IncompleteDiscreteChoice.examples as ex\n",
        "import numpy as np\n",
        "import gdown\n",
        "\n",
        "# Download entrygame sample data (same data as above)\n",
        "url = \"https://drive.google.com/uc?id=1cRhMJ8bRhdzy9_agmQ_LkqzlsKRKcthX\"\n",
        "output = \"data_entrygame.npz\"\n",
        "gdown.download(url, output, quiet=True)\n",
        "Data = np.load(output, allow_pickle=True)\n",
        "\n",
        "# Define the nodes\n",
        "Y_nodes = [(0,0), (0,1), (1,0), (1,1)]\n",
        "U_nodes = ['a', 'b', 'c', 'd', 'e']\n",
        "\n",
        "# Create edges\n",
        "edges = [\n",
        "    ('a', (0,0)),\n",
        "    ('b', (0,1)),\n",
        "    ('c', (1,0)),\n",
        "    ('d', (1,1)),\n",
        "    ('e', (0,1)),\n",
        "    ('e', (1,0))\n",
        "]\n",
        "\n",
        "gmodel = idc.BipartiteGraph(Y_nodes, U_nodes, edges)\n",
        "theta = [0.5, 0.5, -0.25, -0.5, 0.5]\n",
        "Y = Data['Y']\n",
        "X = Data['X']\n",
        "data = [Y, X]\n",
        "Qhat = idc.calculate_Qhat(theta, data, gmodel, ex.calculate_Ftheta_entrygame)\n",
        "print(Qhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLwnDkLHRTsc"
      },
      "source": [
        "You can use `calculate_Qhat` to construct a consistent estimator or construct other test statistics. As an exercise, let's find a minimizer (a point in a consistent set estimator) of this objective function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyAsFqsZRX1z",
        "outputId": "64341364-4d64-416b-d3d8-f8a1744c0c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constraint violated: Ftheta values below 1e-06. Applying penalty.\n",
            "Current Qhat: 0.00035026328249376\n",
            "Convergence: 0.026332234482870615\n",
            "Constraint violated: Ftheta values below 1e-06. Applying penalty.\n",
            "Current Qhat: 0.0003502400318506905\n",
            "Convergence: 0.026493927181952596\n",
            "Current Qhat: 0.00035023945410772583\n",
            "Convergence: 0.034645405856145076\n",
            "Current Qhat: 0.0002614176666387472\n",
            "Convergence: 0.03868531353879789\n",
            "Current Qhat: 0.0002572773233581735\n",
            "Convergence: 0.03821436370375501\n",
            "Current Qhat: 0.00025726585132830636\n",
            "Convergence: 0.037791919870780497\n",
            "Current Qhat: 0.00024860634812482997\n",
            "Convergence: 0.040607332196319866\n",
            "Current Qhat: 0.00021857997285072023\n",
            "Convergence: 0.039661843161200826\n",
            "Current Qhat: 0.00020939305336332439\n",
            "Convergence: 0.04293689056891417\n",
            "Current Qhat: 0.00020419111262286839\n",
            "Convergence: 0.04445149741938285\n",
            "Current Qhat: 0.00020419041451740454\n",
            "Convergence: 0.0459359034979392\n",
            "Current Qhat: 0.00020420011882787834\n",
            "Convergence: 0.051723993145326524\n",
            "Current Qhat: 0.00020418789618088836\n",
            "Convergence: 0.05937982955688446\n",
            "Current Qhat: 0.0001886249620868665\n",
            "Convergence: 0.059766397527173803\n",
            "Current Qhat: 0.00018560202807951353\n",
            "Convergence: 0.08495352967238871\n",
            "Current Qhat: 0.000183731048541034\n",
            "Convergence: 0.08952081107398706\n",
            "Current Qhat: 0.00018110913286710137\n",
            "Convergence: 0.10507450360095462\n",
            "Current Qhat: 0.0001804921169671147\n",
            "Convergence: 0.11409892656661223\n",
            "Current Qhat: 0.000177172665139194\n",
            "Convergence: 0.1383593814693774\n",
            "Current Qhat: 0.00017717165140549452\n",
            "Convergence: 0.14188895400968016\n",
            "Current Qhat: 0.00017689260722576712\n",
            "Convergence: 0.23272515755858103\n",
            "Current Qhat: 0.00017641776787066904\n",
            "Convergence: 0.30506964490643634\n",
            "Current Qhat: 0.00017552577962019232\n",
            "Convergence: 0.356681834957319\n",
            "Current Qhat: 0.00017552534879925288\n",
            "Convergence: 0.4046123012121328\n",
            "Current Qhat: 0.0001753534662292066\n",
            "Convergence: 0.41371477294979964\n",
            "Current Qhat: 0.0001753541588007179\n",
            "Convergence: 0.4405010199572824\n",
            "Current Qhat: 0.00017452655220590661\n",
            "Convergence: 0.49053792720945244\n",
            "Current Qhat: 0.0001739040095316636\n",
            "Convergence: 0.5661593127726879\n",
            "Current Qhat: 0.0001738672384886179\n",
            "Convergence: 0.5799960907644539\n",
            "Current Qhat: 0.00017386589327456477\n",
            "Convergence: 0.5890756057980413\n",
            "Current Qhat: 0.00017379377783830252\n",
            "Convergence: 0.7263182043645189\n",
            "Current Qhat: 0.00017344115761949074\n",
            "Convergence: 0.78729989796263\n",
            "Current Qhat: 0.00017344098512615136\n",
            "Convergence: 0.7982075954110509\n",
            "Current Qhat: 0.00017344128715465477\n",
            "Convergence: 1.203122541761235\n",
            "Optimal theta: [ 0.70865351  0.72455609 -0.0601195  -0.60029877  0.00138245]\n",
            "Minimum Qhat: 0.00017344126108608836\n"
          ]
        }
      ],
      "source": [
        "from scipy.optimize import differential_evolution\n",
        "\n",
        "# Assuming the calculate_Qhat function is already defined as provided earlier\n",
        "\n",
        "# Define the function to minimize\n",
        "def objective_function(theta):\n",
        "    return idc.calculate_Qhat(theta, data, gmodel, ex.calculate_Ftheta_entrygame)\n",
        "\n",
        "# Define the bounds\n",
        "LB = [-2, -2, -2, -2, 0]\n",
        "UB = [2, 2, 0, 0, 0.85]\n",
        "bounds = [(low, high) for low, high in zip(LB, UB)]\n",
        "\n",
        "# Callback function to print intermediate results\n",
        "def callback(xk, convergence):\n",
        "    #print(f\"Current theta: {xk}\")\n",
        "    print(f\"Current Qhat: {objective_function(xk)}\")\n",
        "    print(f\"Convergence: {convergence}\")\n",
        "\n",
        "# Set a seed for replicability\n",
        "np.random.seed(123)\n",
        "\n",
        "# Perform the optimization\n",
        "result = differential_evolution(objective_function, bounds, callback=callback,seed=123)\n",
        "\n",
        "# Get the optimal theta and the minimum Qhat value\n",
        "optimal_theta = result.x\n",
        "min_Qhat = result.fun\n",
        "\n",
        "print(\"Optimal theta:\", optimal_theta)\n",
        "print(\"Minimum Qhat:\", min_Qhat)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}