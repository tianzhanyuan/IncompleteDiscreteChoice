{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkaido0718/IncompleteDiscreteChoice/blob/main/Estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb3pydeIf2G8"
      },
      "source": [
        "# Estimation\n",
        "\n",
        "The goal of this note is to estimate the identified set using a method by Chernozhukov, Hong, and Tamer (2007) (CHT below). Their idea is to define a sample criterion function\n",
        "\\begin{align}\n",
        "\\hat Q_n(\\theta)\n",
        "\\end{align}\n",
        "and use its level set as an estimator of $\\Theta_I(P)$.\n",
        "\n",
        "Below, we\n",
        "- generate data\n",
        "- compute conditional choice probabilities (CCPs)\n",
        "- compare CCPs with the sharp lower bound\n",
        "- define a sample criterion function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja68lsaG-0W8"
      },
      "source": [
        "# Data generation\n",
        "\n",
        "Suppose a sample is generated from an entry game.\n",
        "For this, let's simulate data from the following game.\n",
        "\n",
        "|  | $Y_2=0$ | $Y_2=1$ |\n",
        "|----------|----------|----------|\n",
        "| Enter ($Y_1=0$)  | $(0,0)$   | $(0,X_2'\\beta_2+U_2)$   |\n",
        "| Do not enter ($Y_1=1$)  | $(X_1'\\beta_1+U_1, 0)$  | $(X_1'\\beta_1+\\Delta_1+U_1,X_2'\\beta_2+\\Delta_2+U_2)$  |\n",
        "\n",
        "We set\n",
        "- $X=(X_1,X_2)$ where $X_{j},j=1,2$ are independent Bernoulli random variables.\n",
        "- $\\beta_1$ = 0.75\n",
        "- $\\beta_2$ = 0.25\n",
        "- $\\Delta_1$ = -0.5\n",
        "- $\\Delta_2$ = -0.5\n",
        "- $\\rho$ = 0.5 ($U_1$ and $U_2$'s correlation)\n",
        "\n",
        "The following code generates data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfxkmyqdCtV7",
        "outputId": "30f6391f-3063-49c9-9120-ab3310c039fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [1. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def simulate_y(n, beta1, beta2, delta1, delta2, rho, Y_nodes, seed=None):\n",
        "    \"\"\"\n",
        "    Simulate Y based on given parameters and regions, and store X and Y values.\n",
        "\n",
        "    Parameters:\n",
        "    n (int): Number of simulations\n",
        "    rho (float): Correlation coefficient between U1 and U2\n",
        "    beta1 (float): Coefficient for U1\n",
        "    beta2 (float): Coefficient for U2\n",
        "    delta1 (float): Threshold adjustment for region01\n",
        "    delta2 (float): Threshold adjustment for region10\n",
        "    Y_nodes (list of tuples): Possible values for Y\n",
        "    seed (int, optional): Seed for the random number generator\n",
        "\n",
        "    Returns:\n",
        "    tuple: Two numpy arrays, X_vals and Y, both of shape (n, 2)\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    # Covariance matrix for the bivariate normal distribution\n",
        "    cov = [[1, rho], [rho, 1]]\n",
        "\n",
        "    # Storage for the results\n",
        "    Y = np.zeros((n, 2))\n",
        "    X_vals = np.zeros((n, 2))\n",
        "\n",
        "    # Simulation\n",
        "    for i in range(n):\n",
        "        # Generate U from a bivariate normal distribution\n",
        "        U = np.random.multivariate_normal([0, 0], cov)\n",
        "\n",
        "        # Generate X from independent Bernoulli distributions\n",
        "        X = np.random.binomial(1, 0.5, 2)\n",
        "        #X = np.random.standard_normal(2)\n",
        "        X_vals[i] = X\n",
        "\n",
        "        # Calculate the threshold values for regions\n",
        "        threshold1_00 = -X[0] * beta1\n",
        "        threshold2_00 = -X[1] * beta2\n",
        "        threshold1_01 = -X[0] * beta1 - delta1\n",
        "        threshold2_10 = -X[1] * beta2 - delta2\n",
        "\n",
        "        # Determine the region and assign Y\n",
        "        if U[0] <= threshold1_00 and U[1] <= threshold2_00:\n",
        "            Y[i] = Y_nodes[0]\n",
        "        elif U[0] <= threshold1_01 and U[1] >= threshold2_00 and not (U[0] >= threshold1_00 and U[1] <= threshold2_10):\n",
        "            Y[i] = Y_nodes[1]\n",
        "        elif U[0] >= threshold1_00 and U[1] <= threshold2_10 and not (U[0] <= threshold1_01 and U[1] >= threshold2_00):\n",
        "            Y[i] = Y_nodes[2]\n",
        "        elif U[0] >= threshold1_01 and U[1] >= threshold2_10:\n",
        "            Y[i] = Y_nodes[3]\n",
        "        elif (U[0] <= threshold1_01 and U[1] >= threshold2_00) and (U[0] >= threshold1_00 and U[1] <= threshold2_10):\n",
        "            Y[i] = Y_nodes[np.random.choice([1, 2])]\n",
        "\n",
        "    return X_vals, Y\n",
        "\n",
        "# Example usage\n",
        "n = 1000\n",
        "beta1 = 0.75\n",
        "beta2 = 0.25\n",
        "delta1 = -0.5\n",
        "delta2 = -0.5\n",
        "rho = 0.5\n",
        "theta_true = [beta1, beta2, delta1, delta2, rho]\n",
        "Y_nodes = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
        "seed = 123\n",
        "\n",
        "# Simulate the values\n",
        "X, Y = simulate_y(n, rho, beta1, beta2, delta1, delta2, Y_nodes,seed=seed)\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yhdjBqDhJvd"
      },
      "source": [
        "# Computing CCP\n",
        "Now let's compute the sample conditional choice probabilities, which we can use to construct a sample criterion function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_4pDFqeZl-p",
        "outputId": "512c362c-f187-4e93-c17a-6b8269f46fce"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/hkaido0718/IncompleteDiscreteChoice.git\n",
        "import idclib_undi as idc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvsZ7U9hLne"
      },
      "source": [
        "The idc library has a function called calculate_ccp. For this, we should pass the data ($Y,X$) and their support."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD4rDHsAhLmd",
        "outputId": "0e677a00-b025-40f9-878e-5f1330ce4dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(Y|X=(np.float64(0.0), np.float64(1.0))) = {(0, 0): 0.08171206225680934, (0, 1): 0.3852140077821012, (1, 0): 0.26459143968871596, (1, 1): 0.26848249027237353}\n",
            "P(Y|X=(np.float64(1.0), np.float64(1.0))) = {(0, 0): 0.05982905982905983, (0, 1): 0.15384615384615385, (1, 0): 0.33760683760683763, (1, 1): 0.44871794871794873}\n",
            "P(Y|X=(np.float64(0.0), np.float64(0.0))) = {(0, 0): 0.1857707509881423, (0, 1): 0.2924901185770751, (1, 0): 0.391304347826087, (1, 1): 0.13043478260869565}\n",
            "P(Y|X=(np.float64(1.0), np.float64(0.0))) = {(0, 0): 0.10546875, (0, 1): 0.15625, (1, 0): 0.53515625, (1, 1): 0.203125}\n",
            "[(np.float64(0.0), np.float64(0.0)), (np.float64(0.0), np.float64(1.0)), (np.float64(1.0), np.float64(0.0)), (np.float64(1.0), np.float64(1.0))]\n",
            "[0.253 0.257 0.256 0.234]\n",
            "[[0.18577075 0.29249012 0.39130435 0.13043478]\n",
            " [0.08171206 0.38521401 0.26459144 0.26848249]\n",
            " [0.10546875 0.15625    0.53515625 0.203125  ]\n",
            " [0.05982906 0.15384615 0.33760684 0.44871795]]\n"
          ]
        }
      ],
      "source": [
        "conditional_probabilities,ccp_array, Px, X_supp = idc.calculate_ccp(Y,X, Y_nodes)\n",
        "\n",
        "# Print the conditional probabilities for the specified X support\n",
        "for x in list(conditional_probabilities.keys())[:5]:\n",
        "    print(f\"P(Y|X={x}) = {conditional_probabilities[x]}\")\n",
        "\n",
        "# Support of X and X's marginal distribution over it\n",
        "print(X_supp)\n",
        "print(Px)\n",
        "\n",
        "# This is the CCP matrix (sorted according to X_supp)\n",
        "print(ccp_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUktkjH3zXmC"
      },
      "source": [
        "From the CCP, we can compute the conditional probability of all events $P(A|X_i),A\\subseteq\\mathcal Y$ for each $X_i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aDTNoutXkhWW",
        "outputId": "938537e0-5d8d-428b-b982-a4e40cd3993a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.         0.18577075 0.29249012 0.39130435 0.13043478 0.47826087\n",
            " 0.5770751  0.31620553 0.68379447 0.4229249  0.52173913 0.86956522\n",
            " 0.60869565 0.70750988 0.81422925 1.        ]\n",
            "[[0.         0.18577075 0.29249012 0.39130435 0.13043478 0.47826087\n",
            "  0.5770751  0.31620553 0.68379447 0.4229249  0.52173913 0.86956522\n",
            "  0.60869565 0.70750988 0.81422925 1.        ]\n",
            " [0.         0.08171206 0.38521401 0.26459144 0.26848249 0.46692607\n",
            "  0.3463035  0.35019455 0.64980545 0.6536965  0.53307393 0.73151751\n",
            "  0.73540856 0.61478599 0.91828794 1.        ]\n",
            " [0.         0.10546875 0.15625    0.53515625 0.203125   0.26171875\n",
            "  0.640625   0.30859375 0.69140625 0.359375   0.73828125 0.796875\n",
            "  0.46484375 0.84375    0.89453125 1.        ]\n",
            " [0.         0.05982906 0.15384615 0.33760684 0.44871795 0.21367521\n",
            "  0.3974359  0.50854701 0.49145299 0.6025641  0.78632479 0.55128205\n",
            "  0.66239316 0.84615385 0.94017094 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "_, temp = idc.calculate_subset_probabilities(ccp_array[0,:], Y_nodes)\n",
        "print(temp)\n",
        "J = len(temp) # This is the number of all events\n",
        "\n",
        "Nx = len(ccp_array) # number of unique X values (n for continous X)\n",
        "p_events = np.zeros((Nx,J))\n",
        "for i in range(Nx):\n",
        "  _, p_events[i,:] = idc.calculate_subset_probabilities(ccp_array[i,:], Y_nodes)\n",
        "\n",
        "# Printing p(A|x) as an Nx-by-J array\n",
        "print(p_events)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0ftK4DVZiZW"
      },
      "source": [
        "# Compute sharp lower bound $\\nu_\\theta(A|x)$\n",
        "Now, let's compare $P(A|X_i)$ to the sharp lower bound calculated at some value $\\theta$. For the moment, we use the following value as $\\theta$ (you can change it to something else.)\n",
        "- $\\beta_1$ = 0.5\n",
        "- $\\beta_2$ = 0.5\n",
        "- $\\Delta_1$ = -0.25\n",
        "- $\\Delta_2$ = -0.5\n",
        "- $\\rho$ = 0.5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DYC7rSxcF14"
      },
      "source": [
        "As before let's build a model as a graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CNlRSA4kb1SO"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "Y_nodes = [(0,0), (0,1), (1,0), (1,1)]\n",
        "U_nodes = ['a', 'b', 'c', 'd', 'e']\n",
        "edges = [\n",
        "    ('a', (0,0)),\n",
        "    ('b', (0,1)),\n",
        "    ('c', (1,0)),\n",
        "    ('d', (1,1)),\n",
        "    ('e', (0,1)),\n",
        "    ('e', (1,0))\n",
        "]\n",
        "gmodel = idc.BipartiteGraph(Y_nodes, U_nodes, edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGI0KEdscVAe"
      },
      "source": [
        "The next step is to calculate the probability distribution $F_\\theta(\\cdot|X_i)$ over the $U$-nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_I9N4PTcZhy",
        "outputId": "2480757c-f864-4e54-c4f4-a9f30577f1e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.33333217 0.19694609 0.25122617 0.19659913 0.02189845]\n",
            " [0.22687747 0.32529884 0.14563479 0.28116187 0.02103467]\n",
            " [0.22688203 0.10152299 0.40061467 0.25237197 0.01861066]\n",
            " [0.16331975 0.18369635 0.25212357 0.37986425 0.02099885]]\n"
          ]
        }
      ],
      "source": [
        "import examples as idcex\n",
        "\n",
        "theta_temp = [0.5,0.5,-0.25,-0.5,0.5]\n",
        "Nu = len(U_nodes)\n",
        "Ftheta = np.zeros((Nx,Nu))\n",
        "for i in range(Nx):\n",
        "  Ftheta[i,:] = idcex.calculate_Ftheta_entrygame(X_supp[i],theta_temp)\n",
        "\n",
        "# Print Ftheta as Nx-by-Nu array\n",
        "print(Ftheta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oli2qywycqbj"
      },
      "source": [
        "Now we are ready to compute the sharp lower bound of CCPs at $\\theta$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPFL4Wmucv0G",
        "outputId": "b987f6d2-cac9-4057-d4a7-5642f992a9e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.33333217 0.19694609 0.25122617 0.19659913 0.53027827\n",
            "  0.58455834 0.5299313  0.47007071 0.39354523 0.4478253  0.80340289\n",
            "  0.7268774  0.78115747 0.66666985 1.00000202]\n",
            " [0.         0.22687747 0.32529884 0.14563479 0.28116187 0.55217631\n",
            "  0.37251227 0.50803934 0.49196831 0.60646071 0.42679666 0.71884578\n",
            "  0.83333818 0.65367413 0.77313017 1.00000764]\n",
            " [0.         0.22688203 0.10152299 0.40061467 0.25237197 0.32840503\n",
            "  0.6274967  0.479254   0.52074832 0.35389496 0.65298663 0.74763035\n",
            "  0.58077699 0.87986867 0.77312029 1.00000232]\n",
            " [0.         0.16331975 0.18369635 0.25212357 0.37986425 0.3470161\n",
            "  0.41544331 0.543184   0.45681877 0.56356061 0.63198782 0.62013851\n",
            "  0.72688035 0.79530757 0.83668302 1.00000277]]\n"
          ]
        }
      ],
      "source": [
        "nutheta = np.zeros((Nx,J))\n",
        "for i in range(Nx):\n",
        "    _,nutheta[i,:] = gmodel.calculate_sharp_lower_bound(Ftheta[i])\n",
        "\n",
        "# Print lower bound as Nx-by-J array (compare it to p(A|x) above)\n",
        "print(nutheta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4j6M8yDrDP2"
      },
      "source": [
        "Now let's compare the CCP and lower bounds and compute $\\hat Q_n(\\theta)=\\frac{1}{n}\\sum_{j}\\sum_{x\\in\\mathcal X}w_x(\\nu_\\theta(A_j|x)-\\hat P_n(A_j|x))_+$,\n",
        "where $w_x=\\sum_{i}1\\{X_i=x\\}/n$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQlwG4M2tImH",
        "outputId": "606468ec-6131-46a8-939b-372b7c91035e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0005659745511206443\n"
          ]
        }
      ],
      "source": [
        "difference = nutheta - p_events\n",
        "diff_pos = np.maximum(difference, 0)\n",
        "w = np.repeat(Px,J).reshape(Nx,J)\n",
        "n = len(Y)\n",
        "Qhat = np.sum(w*diff_pos)/n\n",
        "print(Qhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXAGIe0LkAQC"
      },
      "source": [
        "# Summary\n",
        "\n",
        "Let's summarize what we did:\n",
        "- We computed $\\hat p(A|x)$\n",
        "- We computed $\\nu_\\theta(A|x)$ at $\\theta$\n",
        "- We computed $\\hat Q_n(\\theta)$\n",
        "\n",
        "The IDC library has a wrapper function `idc.calculate_Qhat` to execute the steps avove.\n",
        "\n",
        "It takes the following objects as inputs\n",
        "- theta: (parameter)\n",
        "- [Y,X]: (data)\n",
        "- gmodel: (class BipartiteGraph)\n",
        "  - Y-nodes\n",
        "  - U-nodes\n",
        "  - Edges\n",
        "- calculate_Ftheta (function)\n",
        "\n",
        "You can simply execute the following code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmRr59lJnrYV",
        "outputId": "5f621501-58f1-4581-c4a9-541381150f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0005659726519750294\n"
          ]
        }
      ],
      "source": [
        "# If needed uncomment the line below\n",
        "#!git clone https://github.com/hkaido0718/IncompleteDiscreteChoice.git\n",
        "import idclib_undi as idc\n",
        "import examples as ex\n",
        "import numpy as np\n",
        "import gdown\n",
        "\n",
        "# Download entrygame sample data (same data as above)\n",
        "url = \"https://drive.google.com/uc?id=1cRhMJ8bRhdzy9_agmQ_LkqzlsKRKcthX\"\n",
        "output = \"data_entrygame.npz\"\n",
        "gdown.download(url, output, quiet=True)\n",
        "Data = np.load(output, allow_pickle=True)\n",
        "\n",
        "# Define the nodes\n",
        "Y_nodes = [(0,0), (0,1), (1,0), (1,1)]\n",
        "U_nodes = ['a', 'b', 'c', 'd', 'e']\n",
        "\n",
        "# Create edges\n",
        "edges = [\n",
        "    ('a', (0,0)),\n",
        "    ('b', (0,1)),\n",
        "    ('c', (1,0)),\n",
        "    ('d', (1,1)),\n",
        "    ('e', (0,1)),\n",
        "    ('e', (1,0))\n",
        "]\n",
        "\n",
        "gmodel = idc.BipartiteGraph(Y_nodes, U_nodes, edges)\n",
        "theta = [0.5, 0.5, -0.25, -0.5, 0.5]\n",
        "Y = Data['Y']\n",
        "X = Data['X']\n",
        "data = [Y, X]\n",
        "Qhat = idc.calculate_Qhat(theta, data, gmodel, ex.calculate_Ftheta_entrygame)\n",
        "print(Qhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLwnDkLHRTsc"
      },
      "source": [
        "You can use `calculate_Qhat` to construct a consistent estimator or construct other test statistics. As an exercise, let's find a minimizer (a point in a consistent set estimator) of this objective function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyAsFqsZRX1z",
        "outputId": "62766bc9-2696-470a-b10c-0b0f79e3823e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Constraint violated: Ftheta values below 1e-06. Applying penalty.\n",
            "Current Qhat: 0.00035023201491244364\n",
            "Convergence: 0.026332214550073337\n",
            "Constraint violated: Ftheta values below 1e-06. Applying penalty.\n",
            "Current Qhat: 0.0003502509468590959\n",
            "Convergence: 0.026494153434201355\n",
            "Current Qhat: 0.00035026897942469666\n",
            "Convergence: 0.034645048044016746\n",
            "Current Qhat: 0.00026141524830187345\n",
            "Convergence: 0.03868486038886398\n",
            "Current Qhat: 0.00025727287992644016\n",
            "Convergence: 0.03821353902938416\n",
            "Current Qhat: 0.0002572873898080903\n",
            "Convergence: 0.03779148486257911\n",
            "Current Qhat: 0.00024858149399161\n",
            "Convergence: 0.040607225145836784\n",
            "Current Qhat: 0.00021857301315028775\n",
            "Convergence: 0.03966295421603217\n",
            "Current Qhat: 0.00020936771220373158\n",
            "Convergence: 0.04293660777525497\n",
            "Current Qhat: 0.00020418515547418838\n",
            "Convergence: 0.04445181174468144\n",
            "Current Qhat: 0.00020418824884156268\n",
            "Convergence: 0.045934981377470416\n",
            "Current Qhat: 0.00020419879797283082\n",
            "Convergence: 0.05172269278226542\n",
            "Current Qhat: 0.00020418695426657163\n",
            "Convergence: 0.05937935249354952\n",
            "Current Qhat: 0.00018862719518796146\n",
            "Convergence: 0.05976903177116872\n",
            "Current Qhat: 0.0001855977939647595\n",
            "Convergence: 0.08494526956229151\n",
            "Current Qhat: 0.00018372949994391866\n",
            "Convergence: 0.0895205745795321\n",
            "Current Qhat: 0.00018111450759358773\n",
            "Convergence: 0.10507988837963106\n",
            "Current Qhat: 0.0001804817802003675\n",
            "Convergence: 0.11409733375513259\n",
            "Current Qhat: 0.0001771734323043867\n",
            "Convergence: 0.13837749772830657\n",
            "Current Qhat: 0.00017717112771357656\n",
            "Convergence: 0.14191056790674011\n",
            "Current Qhat: 0.00017689280199117266\n",
            "Convergence: 0.23271776363693164\n",
            "Current Qhat: 0.00017641729061131027\n",
            "Convergence: 0.3050375287382135\n",
            "Current Qhat: 0.00017552588285982227\n",
            "Convergence: 0.3567552811723579\n",
            "Current Qhat: 0.00017552652885190111\n",
            "Convergence: 0.40472204625071967\n",
            "Current Qhat: 0.0001753549122201854\n",
            "Convergence: 0.41382564080571116\n",
            "Current Qhat: 0.00017535370530294303\n",
            "Convergence: 0.4405935994525755\n",
            "Current Qhat: 0.00017452643972271285\n",
            "Convergence: 0.49069217388896597\n",
            "Current Qhat: 0.00017390335709992216\n",
            "Convergence: 0.5662063303712678\n",
            "Current Qhat: 0.00017386715259541292\n",
            "Convergence: 0.5800787088506763\n",
            "Current Qhat: 0.00017386707930970065\n",
            "Convergence: 0.589185615831822\n",
            "Current Qhat: 0.0001737937522000771\n",
            "Convergence: 0.7264011408165139\n",
            "Current Qhat: 0.00017344097672801373\n",
            "Convergence: 0.7873903041409657\n",
            "Current Qhat: 0.00017344122745394073\n",
            "Convergence: 0.798271373689145\n",
            "Current Qhat: 0.00017344130725593078\n",
            "Convergence: 1.203288769624563\n",
            "Optimal theta: [ 0.70865351  0.72455609 -0.0601195  -0.60029878  0.00138245]\n",
            "Minimum Qhat: 0.00017344117157685424\n"
          ]
        }
      ],
      "source": [
        "from scipy.optimize import differential_evolution\n",
        "\n",
        "# Assuming the calculate_Qhat function is already defined as provided earlier\n",
        "\n",
        "# Define the function to minimize\n",
        "def objective_function(theta):\n",
        "    return idc.calculate_Qhat(theta, data, gmodel, ex.calculate_Ftheta_entrygame)\n",
        "\n",
        "# Define the bounds\n",
        "LB = [-2, -2, -2, -2, 0]\n",
        "UB = [2, 2, 0, 0, 0.85]\n",
        "bounds = [(low, high) for low, high in zip(LB, UB)]\n",
        "\n",
        "# Callback function to print intermediate results\n",
        "def callback(xk, convergence):\n",
        "    #print(f\"Current theta: {xk}\")\n",
        "    print(f\"Current Qhat: {objective_function(xk)}\")\n",
        "    print(f\"Convergence: {convergence}\")\n",
        "\n",
        "# Set a seed for replicability\n",
        "np.random.seed(123)\n",
        "\n",
        "# Perform the optimization\n",
        "result = differential_evolution(objective_function, bounds, callback=callback,seed=123)\n",
        "\n",
        "# Get the optimal theta and the minimum Qhat value\n",
        "optimal_theta = result.x\n",
        "min_Qhat = result.fun\n",
        "\n",
        "print(\"Optimal theta:\", optimal_theta)\n",
        "print(\"Minimum Qhat:\", min_Qhat)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP/sAq0EcJC4W6uNVRO2iQ9",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
